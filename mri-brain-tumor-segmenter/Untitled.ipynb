{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf26825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting segmentation-models-pytorch\n",
      "  Downloading segmentation_models_pytorch-0.2.1-py3-none-any.whl (88 kB)\n",
      "Collecting pretrainedmodels==0.7.4\n",
      "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
      "Collecting efficientnet-pytorch==0.6.3\n",
      "  Downloading efficientnet_pytorch-0.6.3.tar.gz (16 kB)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in c:\\users\\utric\\anaconda3\\lib\\site-packages (from segmentation-models-pytorch) (0.11.3)\n",
      "Collecting timm==0.4.12\n",
      "  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\utric\\anaconda3\\lib\\site-packages (from efficientnet-pytorch==0.6.3->segmentation-models-pytorch) (1.10.2)\n",
      "Collecting munch\n",
      "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\utric\\anaconda3\\lib\\site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.62.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\utric\\anaconda3\\lib\\site-packages (from torch->efficientnet-pytorch==0.6.3->segmentation-models-pytorch) (3.10.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\utric\\anaconda3\\lib\\site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (8.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\utric\\anaconda3\\lib\\site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.20.3)\n",
      "Requirement already satisfied: six in c:\\users\\utric\\anaconda3\\lib\\site-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\utric\\anaconda3\\lib\\site-packages (from tqdm->pretrainedmodels==0.7.4->segmentation-models-pytorch) (0.4.4)\n",
      "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
      "  Building wheel for efficientnet-pytorch (setup.py): started\n",
      "  Building wheel for efficientnet-pytorch (setup.py): finished with status 'done'\n",
      "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-py3-none-any.whl size=12421 sha256=6e76bbd200be4de982575031a279b04e5b8f3244313a59cb4ab2d7499370ba9d\n",
      "  Stored in directory: c:\\users\\utric\\appdata\\local\\pip\\cache\\wheels\\90\\6b\\0c\\f0ad36d00310e65390b0d4c9218ae6250ac579c92540c9097a\n",
      "  Building wheel for pretrainedmodels (setup.py): started\n",
      "  Building wheel for pretrainedmodels (setup.py): finished with status 'done'\n",
      "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60965 sha256=ab998455bcdb15b2489f62984d4d7f7c47d82bc1191878ca480bae0edda63b62\n",
      "  Stored in directory: c:\\users\\utric\\appdata\\local\\pip\\cache\\wheels\\ed\\27\\e8\\9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\n",
      "Successfully built efficientnet-pytorch pretrainedmodels\n",
      "Installing collected packages: munch, timm, pretrainedmodels, efficientnet-pytorch, segmentation-models-pytorch\n",
      "Successfully installed efficientnet-pytorch-0.6.3 munch-2.5.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.2.1 timm-0.4.12\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "!pip install -U segmentation-models-pytorch\n",
    "import segmentation_models_pytorch as smp\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d22659",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"../input/mridata/\")\n",
    "path_db = Path(\"../input/mridata/database.csv\")\n",
    "path_model_checkpoint = Path(\"./model_checkpoint.pt\")\n",
    "path_best_model = Path(\"./model_best.pt\")\n",
    "# Hyperparameter selection\n",
    "\n",
    "# NN Model\n",
    "dropout = 0.1\n",
    "\n",
    "# Dataset\n",
    "batch_size = 32\n",
    "\n",
    "# optimizer : Adam\n",
    "lr = 0.0002\n",
    "betas = (0.9, 0.99)\n",
    "\n",
    "# Algorithm\n",
    "epochs = 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, csv_file_path, root_dir):\n",
    "        # Saves the entire database : it is relatively small\n",
    "        self.mri_database = pd.read_csv(csv_file_path)\n",
    "        self.images = []\n",
    "        self.segmentation_masks = []\n",
    "        self.labels = []\n",
    "\n",
    "        for i in self.mri_database.index:\n",
    "            image_path = root_dir / self.mri_database[\"image_path\"][i]\n",
    "            mask_path = root_dir / self.mri_database[\"mask_path\"][i]\n",
    "            label = self.mri_database[\"mask\"][i]\n",
    "            \n",
    "            self.images.append(Image.open(image_path))\n",
    "            self.segmentation_masks.append(Image.open(mask_path))\n",
    "            self.labels.append(label)\n",
    "            \n",
    "        self.labels = torch.tensor(self.labels)\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        \n",
    "        self.resize = transforms.Resize((128, 128))\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mri_database)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image = self.images[item]\n",
    "        mask = self.segmentation_masks[item]\n",
    "        label = self.labels[item]\n",
    "                \n",
    "        image = self.resize(image)\n",
    "        mask = self.resize(mask)\n",
    "        \n",
    "        rotation = (2*np.random.rand()-1)*20\n",
    "        translate_x = np.round((2*np.random.rand()-1)*0.05*224)\n",
    "        translate_y = np.round((2*np.random.rand()-1)*0.05*224)\n",
    "        \n",
    "        image = transforms.functional.affine(image, rotation, (translate_x, translate_y), 1, 0)\n",
    "        mask = transforms.functional.affine(mask, rotation, (translate_x, translate_y), 1, 0)\n",
    "        \n",
    "        flip = np.random.rand()>0.5\n",
    "        if flip:\n",
    "            image = transforms.functional.hflip(image)\n",
    "            mask = transforms.functional.hflip(mask)\n",
    "        \n",
    "        image = self.normalize(self.to_tensor(image))\n",
    "        mask = self.to_tensor(mask)\n",
    "        mask = torch.round(mask)\n",
    "                  \n",
    "        return image, mask, label\n",
    "    \n",
    "    def show(self, item):\n",
    "        im, mk, label = self[item]\n",
    "        im = im.permute(1, 2, 0).numpy()\n",
    "        mk = mk.permute(1, 2, 0).numpy()\n",
    "        \n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        \n",
    "        im = std * im + mean\n",
    "        im = np.clip(im, 0, 1)\n",
    "        \n",
    "        im = np.where(mk, np.array([[255,0,0]]), im)\n",
    "\n",
    "        plt.imshow(im)\n",
    "        plt.title(f\"Label: {'tumor' if label else 'no tumor'}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4243e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_dataset = MRIDataset(path_db, root)\n",
    "mri_dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deea3139",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.bloc = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3,  padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.bloc(x)\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout):\n",
    "        super().__init__()\n",
    "        self.double_conv_layer = DoubleConvLayer(in_channels, out_channels)\n",
    "        self.maxpool_layer = nn.MaxPool2d((2, 2))\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        skip = self.double_conv_layer(x)\n",
    "        down = self.maxpool_layer(skip)\n",
    "        down = self.dropout_layer(down)\n",
    "        return down, skip\n",
    "    \n",
    "class BottleneckLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout):\n",
    "        super().__init__()\n",
    "        self.double_conv_layer = DoubleConvLayer(in_channels, out_channels)\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        out = self.double_conv_layer(x)\n",
    "        out = self.dropout_layer(out)\n",
    "        return out\n",
    "        \n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout):\n",
    "        super().__init__()\n",
    "        self.up_layer = nn.ConvTranspose2d(in_channels-out_channels, in_channels-out_channels, kernel_size=2, stride=2)\n",
    "        self.double_conv_layer = DoubleConvLayer(in_channels, out_channels)\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, down, skip):\n",
    "        up = self.up_layer(down)\n",
    "        up = torch.cat([up, skip], dim=1)\n",
    "        up = self.double_conv_layer(up)\n",
    "        up = self.dropout_layer(up)\n",
    "        return up\n",
    "        \n",
    "class SegUNet(nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super(SegUNet, self).__init__()\n",
    "        self.encoder_1 = EncoderLayer(3, 64, dropout)\n",
    "        self.encoder_2 = EncoderLayer(64, 128, dropout)\n",
    "        self.encoder_3 = EncoderLayer(128, 256, dropout)\n",
    "        \n",
    "        self.bottleneck = BottleneckLayer(256, 512, dropout)\n",
    "        \n",
    "        self.decoder_3 = DecoderLayer(512+256, 256, dropout)\n",
    "        self.decoder_2 = DecoderLayer(256+128, 128, dropout)\n",
    "        self.decoder_1 = DecoderLayer(128+64, 64, dropout)\n",
    "        \n",
    "        self.final_layer = nn.Conv2d(64, 1, kernel_size=1)\n",
    "        self.output_layer = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x, skip1 = self.encoder_1(x)\n",
    "        x, skip2 = self.encoder_2(x)\n",
    "        x, skip3 = self.encoder_3(x)\n",
    "        x = self.bottleneck(x)\n",
    "        x = self.decoder_3(x, skip3)\n",
    "        x = self.decoder_2(x, skip2)\n",
    "        x = self.decoder_1(x, skip1)\n",
    "        x = self.final_layer(x)\n",
    "        return self.output_layer(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657429f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNTrainer:\n",
    "#     model, optimizer, criterion, device, lr_scheduler, path_model_checkpoint, False\n",
    "    def __init__(self, model, optimizer, criterion, device, lr_scheduler=None, \n",
    "                 path_best_model: Path = None, path_model_checkpoint: Path = None, from_checkpoint = True):\n",
    "        self.path_model_checkpoint = path_model_checkpoint\n",
    "        self.best_model_path = path_best_model\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.loss = []\n",
    "        \n",
    "        self.metrics = []\n",
    "        self.iou = smp.utils.metrics.IoU(threshold=0.5)\n",
    "\n",
    "        # Check if model already exists\n",
    "        if from_checkpoint:\n",
    "            if path_model_checkpoint.is_file():\n",
    "                self.load_checkpoint()\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        checkpoint_data = {'epoch': self.epoch,\n",
    "                           'model_state_dict': self.model.state_dict(),\n",
    "                           'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                           'loss': self.loss,\n",
    "                           'iou': self.iou,\n",
    "                           }\n",
    "\n",
    "        torch.save(checkpoint_data, self.path_model_checkpoint)\n",
    "        \n",
    "    def _save_if_best(self):\n",
    "        # \"Best\" defined by f1 score on \"tumor\" class detection\n",
    "        iou = np.array([x[\"iou\"] for x in  self.metrics])\n",
    "        if iou[-1] == np.max(iou):\n",
    "            torch.save({'model_state_dict': self.model.state_dict()}, self.best_model_path)\n",
    "            \n",
    "    def load_checkpoint(self):\n",
    "        checkpoint = torch.load(self.path_model_checkpoint)\n",
    "\n",
    "        self.epoch = checkpoint[\"epoch\"]\n",
    "        self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        self.loss = checkpoint[\"loss\"]\n",
    "        self.metrics = checkpoint[\"metrics\"]\n",
    "        \n",
    "        print(f\"Model updated using parameters from: {self.path_model_checkpoint}\")\n",
    "\n",
    "    def train(self, train_loader, validation_loader, n_epochs, verbose=False,):\n",
    "        # Loop through epochs\n",
    "        for epoch in tqdm(range(n_epochs),  desc=\"Epochs\"):\n",
    "            loss_sublist = []\n",
    "\n",
    "            # Training\n",
    "            self.model.train()\n",
    "            for x, y, _ in train_loader:\n",
    "                # x: image, y: mask, _: label\n",
    "                self.optimizer.zero_grad()\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                out = self.model(x)\n",
    "                \n",
    "                loss = self.criterion(out, y)\n",
    "                loss_sublist.append(loss.data.item())\n",
    "                \n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "            self.loss.append(np.mean(loss_sublist))\n",
    "            if self.lr_scheduler:\n",
    "                self.lr_scheduler.step()\n",
    "            \n",
    "            # Model evaluation\n",
    "            self.model.eval()\n",
    "            predictions = []\n",
    "            ground_truths = []\n",
    "            \n",
    "            loss = []\n",
    "            iou = []\n",
    "            \n",
    "            for x, y, _ in validation_loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                out = self.model(x)\n",
    "                \n",
    "                loss.append(self.criterion(out,y).item())\n",
    "                iou.append(self.iou(out,y).item())\n",
    "                \n",
    "            iou = np.mean(iou)\n",
    "            loss = np.mean(loss)\n",
    "            \n",
    "            self.metrics.append({'iou': iou,\n",
    "                                'loss':loss})\n",
    "            self.epoch += 1\n",
    "            self.save_checkpoint()\n",
    "            self._save_if_best()\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"*\"*25)\n",
    "                print(f\"Summary epoch {self.epoch}:\")\n",
    "                print(f\"----Loss train:     \\t{self.loss[-1]:.3f} \")\n",
    "                print(f\"----Loss val:       \\t{self.metrics[-1]['loss']:.3f}\")\n",
    "                print(f\"----IoU val:        \\t{self.metrics[-1]['iou']:.3f}\")\n",
    "\n",
    "    def report(self, title=None):\n",
    "        \"\"\"\n",
    "        Make a reporting with three plots :\n",
    "            1) loss and accuracy VS epoch\n",
    "            2) \"No tumor\" label: Recall VS Precision as a function of epoch\n",
    "            3)  \"Tumor\"   label: Recall VS Presision as a function of epoch\n",
    "        \"\"\"\n",
    "        \n",
    "        loss_trn = self.loss\n",
    "        loss_val =  np.array([x['loss'] for x in self.metrics])\n",
    "        iou = np.array([x['iou'] for x in self.metrics])\n",
    "        \n",
    "        \n",
    "        fig, ax = plt.subplots(1, 2, figsize=(15/2.54, 8/2.54))\n",
    "        ax[0].plot(loss_trn, \"-o\", color='tab:red', label=\"Train\")\n",
    "        ax[0].plot(loss_val, \"-o\", color='tab:blue', label=\"Val\")\n",
    "        ax[0].legend()\n",
    "        ax[0].set_ylabel(\"Loss\")\n",
    "        ax[0].set_xlabel(\"Epoch\")\n",
    "\n",
    "\n",
    "        ax[1].plot(iou, color='tab:blue')\n",
    "        ax[1].set_ylim(0,1)\n",
    "        ax[1].set_xlabel(\"Epoch\")\n",
    "        ax[1].set_ylabel(\"IoU\")\n",
    "        \n",
    "        if title:\n",
    "            fig.suptitle(title)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea84da86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid data leakage between the train_set and the valid_set between training sessions,\n",
    "# DO NOT change the seed !\n",
    "train_set_size = int(len(mri_dataset) * 0.85)\n",
    "valid_set_size = len(mri_dataset) - train_set_size\n",
    "\n",
    "\n",
    "train_set, valid_set = random_split(mri_dataset, [train_set_size, valid_set_size],\n",
    "                                    generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(dataset=valid_set, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c0352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SegUNet(dropout=dropout)\n",
    "model.to(device)\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=betas)\n",
    "# lr_scheduler = optim.lr_scheduler.CyclicLR(optimizer, base_lr=base_lr, max_lr=max_lr, step_size_up=5, mode=\"triangular2\")\n",
    "lr_scheduler = None\n",
    "criterion = smp.utils.losses.DiceLoss()\n",
    "\n",
    "\n",
    "mri_net_trainer = NNTrainer(model, optimizer, criterion, device, lr_scheduler, path_best_model, path_model_checkpoint, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65814aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_net_trainer.train(train_loader, validation_loader, 20, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73c61ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_net_trainer.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd27992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, device, im, mk):\n",
    "    model.eval()\n",
    "    im_ = im\n",
    "    im, mk = im.to(device), mk.to(device)\n",
    "    im_= torch.unsqueeze(im,0)\n",
    "    pd = torch.squeeze(model(im_), 0)\n",
    "    \n",
    "    print(pd.size())\n",
    "    \n",
    "    im = im.cpu().permute(1, 2, 0).numpy()\n",
    "    mk = mk.cpu().permute(1, 2, 0).numpy()\n",
    "    pd = pd.cpu().permute(1, 2, 0).detach().numpy()\n",
    "    \n",
    "    \n",
    "    pd = np.round(pd)\n",
    "    \n",
    "\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "    im = std * im + mean\n",
    "    im = np.clip(im, 0, 1)\n",
    "\n",
    "#     im = np.where(mk, np.array([[255,0,0]]), im)\n",
    "    fig, ax = plt.subplots(1,3,figsize=(12,8))\n",
    "\n",
    "    ax[0].imshow(im)\n",
    "    ax[1].imshow(mk)\n",
    "    ax[2].imshow(pd)\n",
    "    ax[0].set_title(\"MRI\")\n",
    "    ax[1].set_title(\"Ground truth\")\n",
    "    ax[2].set_title(\"Prediction\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d859fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "j=1\n",
    "for i in range(100):\n",
    "    im, mk, lb = mri_dataset[i]\n",
    "    \n",
    "    if lb:\n",
    "        test_model(model, device, im, mk)\n",
    "        j+=1\n",
    "    if i>=5 :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ee017b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
